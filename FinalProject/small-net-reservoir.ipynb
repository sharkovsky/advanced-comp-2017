{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoir Computing\n",
    "### EPFL - Advanced Computing course 2017\n",
    "\n",
    "_Francesco Cremonesi_\n",
    "\n",
    "This is the code accompanying my project report. This code uses [pyNEST](http://www.nest-simulator.org/) to instantiate a simulation of leaky integrate-and-fire neurons, which is used as a reservoir for learning a text generation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nest\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up of NEST\n",
    "\n",
    "Set the number of threads to speed up simulations (caveat: setting this to the maximum number of threads is not always the best option, since NEST is mainly a memory-bound code).\n",
    "\n",
    "Moreover, I have tried without success to initialize all the random seeds, to make sure that NEST's behaviour is reproducible. After some trial and error, I was forced to give up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nest.ResetKernel()\n",
    "nest.SetKernelStatus({\"local_num_threads\": 8})\n",
    "nest.set_verbosity('M_FATAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msd = 123456\n",
    "N_vp = nest.GetKernelStatus(['total_num_virtual_procs'])[0]\n",
    "\n",
    "pyrngs = [np.random.RandomState(s) for s in range(msd, msd+N_vp)]\n",
    "\n",
    "nest.SetKernelStatus({'grng_seed' : msd+N_vp})\n",
    "nest.SetKernelStatus({'rng_seeds' : range(msd+N_vp+1, msd+2*N_vp+1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputf = h5py.File('../../lua-torch/dante/data/dante.h5','r')\n",
    "input_seq = inputf['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 77 tokens\n"
     ]
    }
   ],
   "source": [
    "inputjson = open('../../lua-torch/dante/data/dante.json','r')\n",
    "jsondata = json.load( inputjson )\n",
    "ntokens = max( [ int(x) for x in jsondata['idx_to_token'].keys()] )\n",
    "print 'there are', ntokens, 'tokens'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation configuration\n",
    "\n",
    "#### Number of neurons and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 0.1    # the resolution in ms\n",
    "delay = 0.3    # synaptic delay in ms\n",
    "\n",
    "N_neurons = 5000\n",
    "\n",
    "N_rec = int(0.4*N_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_tot = int(0.1*N_neurons)\n",
    "\n",
    "tauMem = 20.0  # time constant of membrane potential in ms\n",
    "theta = 20.0  # membrane threshold potential in mV\n",
    "J = 3.0   # postsynaptic amplitude in mV\n",
    "g = 5.0\n",
    "tau_syn = 0.6\n",
    "neuron_params = {\"C_m\": 1.0,\n",
    "                 \"tau_m\": tauMem,\n",
    "                 \"t_ref\": 0.4,\n",
    "                 \"E_L\": 0.0,\n",
    "                 \"V_reset\": 0.0,\n",
    "                 \"V_m\": 0.0,\n",
    "                 \"V_th\": theta,\n",
    "                 \"tau_syn_ex\": tau_syn,\n",
    "                 \"tau_syn_in\": tau_syn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stimulation times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your chosen max_simtime: 400000.0  ms\n",
      "corresponds to  20000 characters analyzed in the text\n"
     ]
    }
   ],
   "source": [
    "single_input_stimul_time = 5.0\n",
    "single_input_quiet_time = 15.0\n",
    "single_input_sim_time = single_input_stimul_time + single_input_quiet_time\n",
    "\n",
    "# there are 661393 characters in the text\n",
    "n_char_input = 20000.0\n",
    "max_simtime = n_char_input*single_input_sim_time\n",
    "\n",
    "print ' your chosen max_simtime:', max_simtime, ' ms'\n",
    "print 'corresponds to ', \\\n",
    "      int(max_simtime/single_input_sim_time), \\\n",
    "    'characters analyzed in the text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nest.SetKernelStatus({\"resolution\": dt, \"print_time\": True,\n",
    "                      \"overwrite_files\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the network\n",
    "\n",
    "#### Create excitatory and inhibitory neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nest.SetDefaults(\"iaf_psc_exp\", neuron_params)\n",
    "\n",
    "nodes_ex = nest.Create(\"iaf_psc_exp\",int(0.8*N_neurons))\n",
    "nodes_in = nest.Create(\"iaf_psc_exp\",int(0.2*N_neurons))\n",
    "nodes = nodes_ex + nodes_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create inputs\n",
    "\n",
    "An input will inject a random sequence of external spikes into a subset of the neurons. Different inputs correspond to different tokens in the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(ntokens):\n",
    "    inputs.append(nest.Create(\"poisson_generator\"))\n",
    "    nest.SetStatus( inputs[ i ], {\"rate\": 0.0} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nest.CopyModel(\"static_synapse\", \"excitatory\", {\"delay\": delay})\n",
    "nest.CopyModel(\"static_synapse\", \"inhibitory\", {\"delay\": delay})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect the inputs\n",
    "\n",
    "1. randomly select a subset of neurons per token. The number of neurons associated with each token is given by the variable `N_nodes_per_input`;\n",
    "2. connect each input to the corresponding neurons;\n",
    "3. initialize the spiking rate of each input to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_nodes_per_input = 4\n",
    "index_of_nodes_that_receive_input = np.random.choice(N_neurons, N_nodes_per_input*ntokens, replace=False)\n",
    "nodes_that_receive_input = [x for i,x in enumerate(nodes) if i in index_of_nodes_that_receive_input]\n",
    "\n",
    "for i in range(ntokens):\n",
    "    nest.Connect( inputs[i], \n",
    "                 nodes_that_receive_input[N_nodes_per_input*i:N_nodes_per_input*(i+1)], \n",
    "                 syn_spec=\"excitatory\")\n",
    "    nest.SetStatus( inputs[i], {\"rate\": 0.0} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the readouts\n",
    "\n",
    "First, create an instance of a spike detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spikes = nest.Create(\"spike_detector\")\n",
    "\n",
    "nest.SetStatus(spikes, [{\"label\": \"readout\",\n",
    "                          \"withtime\": True,\n",
    "                          \"withgid\": True,\n",
    "                          \"to_memory\": True,\n",
    "                          \"to_file\": False}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect the readouts\n",
    "\n",
    "select a subset of `N_rec` neurons that will act as readout neurons. Connect each one to the spike detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_of_nodes_that_provide_output = np.random.choice(N_neurons, N_rec, replace=False)\n",
    "nodes_that_provide_output = [x for i,x in enumerate(nodes) if i in index_of_nodes_that_provide_output]\n",
    "nest.Connect( nodes_that_provide_output, spikes, syn_spec=\"excitatory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the connectivity\n",
    "\n",
    "I choose to connect the neurons with a random weight drawn from a normal distribution. As is customary for a balanced network, the inhibitory weights are stronger than the excitatory ones, but there are less inhibitory connections in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syn_params_ex = {\"model\": \"excitatory\", \"weight\": {'distribution': 'normal', 'mu': J, 'sigma':1.0}}\n",
    "syn_params_in = {\"model\": \"inhibitory\", \"weight\": {'distribution': 'normal', 'mu': -g*J, 'sigma':1.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the connections between neurons\n",
    "\n",
    "Connections obey the following rules:\n",
    "- each neuron receives exactly `indegree` connections;\n",
    "- excitatory neurons only make excitatory __outgoing__ connections, and vice versa for inhibitory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn_params_ex = {'rule': 'fixed_indegree', 'indegree': int(0.8*C_tot)}\n",
    "nest.Connect(nodes_ex, nodes, conn_params_ex, syn_params_ex)\n",
    "\n",
    "conn_params_in = {'rule': 'fixed_indegree', 'indegree': int(0.2*C_tot)}\n",
    "nest.Connect(nodes_in, nodes, conn_params_in, syn_params_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate!\n",
    "\n",
    "The basic simulation loop is the following:\n",
    "1. get the corresponding character in the input sequence, whose token value is `input_idx`;\n",
    "2. activate the corresponding input with a frequency of 100Hz, for a period of time of duration `single_input_stimul_time`;\n",
    "3. silnce the input, and let the network evolve for a period of duration `single_input_quiet_time`;\n",
    "4. if maximum time has not been reached, repeat from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_metadata = list()\n",
    "simtime = 0.0\n",
    "\n",
    "for j, input_idx in enumerate(input_seq):\n",
    "    sequence_metadata.append( ( j*single_input_sim_time, (j+1)*single_input_sim_time, input_idx) )\n",
    "    \n",
    "    nest.SetStatus( inputs[ input_idx - 1 ], {\"rate\": 100000.0} )\n",
    "    nest.Simulate(single_input_stimul_time)\n",
    "    simtime += single_input_stimul_time\n",
    "\n",
    "    nest.SetStatus( inputs[ input_idx - 1 ], {\"rate\": 0.0} )   \n",
    "    nest.Simulate(single_input_quiet_time)\n",
    "    simtime += single_input_quiet_time\n",
    "    \n",
    "    if simtime >= max_simtime:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve all the spikes from the detector\n",
    "\n",
    "And sort them for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_spikes(detector):\n",
    "    dSD = nest.GetStatus(detector,keys=\"events\")[0]\n",
    "    spike_times = np.array(dSD[\"senders\"])\n",
    "    spike_times = np.c_[ spike_times, np.array(dSD[\"times\"]) ]\n",
    "    spike_times =spike_times[ spike_times[:,1].argsort() ]\n",
    "    return spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted  12814666  spikes\n"
     ]
    }
   ],
   "source": [
    "spike_times = get_all_spikes(spikes)\n",
    "\n",
    "print 'Counted ', spike_times.shape[0], ' spikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brunel network simulation (Python)\n",
      "Number of neurons : 5000\n",
      "Number of synapses: 2002308\n",
      "Firing rate       : 16.02 Hz\n"
     ]
    }
   ],
   "source": [
    "events = nest.GetStatus(spikes, \"n_events\")[0]\n",
    "\n",
    "rate = events / simtime * 1000.0 / N_rec\n",
    "\n",
    "num_synapses = (nest.GetDefaults(\"excitatory\")[\"num_connections\"])\n",
    "\n",
    "print(\"Brunel network simulation (Python)\")\n",
    "print(\"Number of neurons : {0}\".format(N_neurons))\n",
    "print(\"Number of synapses: {0}\".format(num_synapses))\n",
    "print(\"Firing rate       : %.2f Hz\" % rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two different ways of generating a raster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import nest.raster_plot\n",
    "#nest.raster_plot.from_device(spikes, hist=True)\n",
    "#print simtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(spike_times[:10000,1], spike_times[:10000,0], 'ob', markersize=0.9)\n",
    "#plt.xlim((0,simtime))\n",
    "#plt.xlim((0,300))\n",
    "plt.xlabel('time (ms)')\n",
    "plt.ylabel('gid of neuron')\n",
    "plt.savefig('raster-smallStimTimes.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the readouts with Ridge Regression\n",
    "\n",
    "In the second phase, we gather all the spike outputs, parse them in a meaningful way and train the readout weights using ridge regression.\n",
    "\n",
    "I define a `line_offset` because the network's initial conditions might have an effect that I wish to ignore. Basically `line_offset` is equal to the number of input character I wish to ignore at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted  20000  sequences\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "nseq = len(sequence_metadata)\n",
    "nreadout = N_rec\n",
    "line_offset = 10\n",
    "time_window = 7.0*single_input_sim_time\n",
    "\n",
    "print 'Counted ', nseq, ' sequences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design and Output matrix\n",
    "\n",
    "$X $ is going to be the design matrix. Actually, \n",
    "\n",
    "$X = [\\tilde{X}; U; 1] $ \n",
    "\n",
    "where: \n",
    "- $\\tilde{X}_{ij} $ is the firing frequency of the $i^{th} $ readout neuron, during the $j^{th} $ time window;\n",
    "- $U_{ij} $ is 1 if the $i^{th} $ token was the last to be presented during the $j^{th} $ time window, 0 otherwise.\n",
    "\n",
    "On the other hand, $Y_{ij} $ is 1 if the $i^{th} $ token is the first to be presented __after__ $j^{th} $ time window, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros( shape=(nreadout + ntokens + 1, nseq-line_offset-1) )\n",
    "Y = np.zeros( shape=(ntokens, nseq-line_offset-1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill $X$ and $Y$, I am going to iterate over the output spikes, computing a firing frequency (in kHz) and insert the value in the corresponding matrix element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x(spike_times, unique_gids, endtime, time_window):\n",
    "    gids = spike_times[ np.logical_and( \n",
    "            spike_times[:,1] <= endtime, \n",
    "            spike_times[:,1] >= endtime - time_window), 0 ]\n",
    "\n",
    "    x, _ = np.histogram( gids, bins=unique_gids) \n",
    "    x = np.lib.pad(x,(0,nreadout - len(unique_gids) +1 ), 'constant', constant_values=(0,0) )\n",
    "    x = x*1.0/time_window\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_CAUTION_ the following cell may be very time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete\n",
      "9.99549752364 % complete\n",
      "19.9909950473 % complete\n",
      "29.9864925709 % complete\n",
      "39.9819900946 % complete\n",
      "49.9774876182"
     ]
    }
   ],
   "source": [
    "unique_gids = np.sort( np.unique( spike_times[ :, 0] ) )\n",
    "\n",
    "tt = (line_offset+1)*single_input_sim_time\n",
    "\n",
    "for i in range(nseq-line_offset-1):\n",
    "    if i % int(0.1*(nseq-line_offset-1)) == 0:\n",
    "        print float(i)/(nseq-line_offset-1)*100.0, '% complete'\n",
    "    xx = get_x(spike_times, unique_gids, tt, time_window)\n",
    "    u_idx = sequence_metadata[i+line_offset][2]\n",
    "    uu = np.zeros(shape=(ntokens,))\n",
    "    uu[u_idx - 1] = 1.0\n",
    "    X[:,i] = np.r_[xx,uu, 1.0]\n",
    "    metadata = sequence_metadata[i+line_offset+1]\n",
    "    token_to_predict = metadata[2]\n",
    "    Y[token_to_predict-1, i] = 1\n",
    "    tt += single_input_sim_time\n",
    "    \n",
    "orig_X = np.array(X, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a utility cell to test out different training scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. standard reservoir training scenario\n",
    "X = np.array(orig_X, copy=True)\n",
    "\n",
    "# 2. no reservoir\n",
    "#X = np.array(orig_X, copy=True)\n",
    "#X[nreadout:,:] = 0.\n",
    "\n",
    "# 3. no input concatenation\n",
    "#X = np.array(orig_X, copy=True)\n",
    "#X[:nreadout,:] = 0.\n",
    "\n",
    "# 4. no constant term only\n",
    "#X = np.array(orig_X, copy=True)\n",
    "#X[:-1,:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(X[:,:2000])\n",
    "plt.colorbar()\n",
    "#plt.savefig('X-noU.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Readout Weights\n",
    "\n",
    "We perform ridge regression, which means Least Squares + L2 regularization term.\n",
    "\n",
    "Therefore, we have the following formula:\n",
    "\n",
    "$$ W = YX^T(XX^T + \\beta I)^{-1} $$\n",
    "\n",
    "where $\\beta$ is the regularization coefficient.\n",
    "\n",
    "To be clear, $W$ should have shape `ntokens`-by-`nreadout`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "\n",
    "grahm = np.dot(X, X.T)\n",
    "grahm += beta*np.eye( nreadout + ntokens + 1 )\n",
    "\n",
    "W = Y.dot( X.T.dot( inv( grahm ) ) )\n",
    "\n",
    "print W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "grahm = np.dot(X, X.T)\n",
    "plt.imshow(grahm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grahm += beta*np.eye( nreadout )\n",
    "#plt.figure(figsize=(12,12))\n",
    "#plt.imshow(grahm)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp = inv( grahm ) \n",
    "#plt.figure(figsize=(12,12))\n",
    "#plt.imshow(tmp)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp = X.T.dot( inv( grahm ) ) \n",
    "#plt.figure(figsize=(12,12))\n",
    "#plt.imshow(tmp)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,12))\n",
    "plt.imshow(Y[:,:400], interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,8))\n",
    "plt.imshow(W[:,-400:])\n",
    "plt.colorbar()\n",
    "#plt.savefig('W-smallB.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from a new sequence\n",
    "\n",
    "#### Input a seed sequence\n",
    "\n",
    "I haven's observed big differences between long or short input sequences, but to avoid initialization effects it might be better to use at least 5-10 characters in the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Input a sequence to start sampling'\n",
    "sample_seq = raw_input()\n",
    "\n",
    "if not sample_seq:\n",
    "    assert False\n",
    "\n",
    "sample_seq = [ jsondata['token_to_idx'][x] for x in sample_seq ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run the simulation corresponding to the inputs from the seed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(ntokens):\n",
    "    nest.SetStatus( inputs[i], {\"rate\": 0.0} )\n",
    "    \n",
    "resting_time = 200.0\n",
    "nest.Simulate(resting_time)\n",
    "\n",
    "for j, input_idx in enumerate(sample_seq):\n",
    "    nest.SetStatus( inputs[ input_idx - 1 ], {\"rate\": 100000.0} )\n",
    "    nest.Simulate(single_input_stimul_time)\n",
    "    simtime += single_input_stimul_time\n",
    "\n",
    "    nest.SetStatus( inputs[ input_idx - 1 ], {\"rate\": 0.0} )   \n",
    "    nest.Simulate(single_input_quiet_time)\n",
    "    simtime += single_input_quiet_time\n",
    "\n",
    "nest.SetStatus( inputs[ sample_seq[-1] -1 ], {\"rate\": 0.0} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spike_times = get_all_spikes(spikes)\n",
    "\n",
    "print 'Counted ', spike_times.shape[0], ' spikes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation!\n",
    "\n",
    "In this phase, the next predicted character is fed back to the network as input for the next simulation sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "for i in range(ntokens):\n",
    "    nest.SetStatus( inputs[i], {\"rate\": 0.0} )\n",
    "\n",
    "len_sample = 200\n",
    "\n",
    "old_input_idx = sample_seq[-1]\n",
    "\n",
    "for t in range(len_sample):\n",
    "    # predict next character\n",
    "    spike_times = get_all_spikes(spikes)\n",
    "    xx = get_x( spike_times, unique_gids, simtime, time_window)\n",
    "    uu = np.zeros(shape=(ntokens,))\n",
    "    uu[old_input_idx - 1] = 1.0\n",
    "    x = np.r_[xx,uu,1.0]\n",
    "    c_idx = np.argmax( np.dot( W, x ) )\n",
    "    predicted_char = jsondata['idx_to_token'][ str( c_idx + 1) ]\n",
    "#    print '=============> ', repr( predicted_char )\n",
    "    sys.stdout.write(predicted_char)\n",
    "    old_input_idx = c_idx + 1\n",
    "    # feedback\n",
    "    input_val = int( jsondata['token_to_idx'][predicted_char] )\n",
    "    nest.SetStatus( inputs[ input_val - 1 ], {\"rate\": 100000.0} )\n",
    "\n",
    "    # simulate\n",
    "    nest.Simulate(single_input_stimul_time)\n",
    "    simtime += single_input_stimul_time\n",
    "    \n",
    "    nest.SetStatus( inputs[ input_val - 1 ], {\"rate\": 0.0} )\n",
    "\n",
    "    # simulate\n",
    "    nest.Simulate(single_input_quiet_time)\n",
    "    simtime += single_input_quiet_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
