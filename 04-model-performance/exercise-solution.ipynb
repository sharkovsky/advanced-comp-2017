{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Work on this before the next lecture on 1 May. We will talk about questions, comments, and solutions during the exercise after the third lecture.\n",
    "\n",
    "Please do form study groups! When you do, make sure you can explain everything in your own words, do not simply copy&paste from others.\n",
    "\n",
    "The solutions to a lot of these problems can probably be found with Google. Please don't. You will not learn a lot by copy&pasting from the internet.\n",
    "\n",
    "If you want to get credit/examination on this course please upload your work to **your GitHub repository** for this course **before** the next lecture starts and post a link to your repository [in this thread](). If you worked on things together with others please add their names to the notebook so we can see who formed groups.\n",
    "\n",
    "---\n",
    "\n",
    "These are some useful default imports for plotting and [`numpy`](http://www.numpy.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pitfalls of estimating model performance\n",
    "\n",
    "This question sets up a classification problem to illustrate a common pitfall in\n",
    "evaluating model performance. To keep things simple the `y`s in this class room problem\n",
    "are picked at random: there is no way for a classifier to learn how to model `y` based\n",
    "on the features provided. This means we know what the true accuracy is: 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "np.random.seed(6450345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A common task when building a new model is to select only those variables that are \"best\"\n",
    "for the problem. This selection procedure can take many different shapes, here we will\n",
    "compute the correlation of each feature with the target, select the 20 features that\n",
    "have the highest correlation and use those in our gradient boosted tree ensemble.\n",
    "\n",
    "We will then use cross validation to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on each subset:\n",
      "[ 0.60349127  0.63092269  0.5975      0.63157895  0.65413534]\n",
      "Average score and uncertainty: (62.35 +- 0.924)%\n"
     ]
    }
   ],
   "source": [
    "def make_data(N=1000, n_vars=10,\n",
    "              n_classes=2):\n",
    "    X = np.random.normal(size=(N,n_vars))\n",
    "    y = np.random.choice(n_classes, N)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X,y = make_data(N=2000, n_vars=50000)\n",
    "\n",
    "select = SelectKBest(f_regression, k=20)\n",
    "X_sel = select.fit_transform(X, y)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, X_sel, y, cv=5, n_jobs=8)\n",
    "\n",
    "print(\"Scores on each subset:\")\n",
    "print(scores)\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What just happened? We have a classifier that achieves and accuracy of ~60% but we know that the features are uncorrelated with the target. How did this happen? What mistake did we make?\n",
    "\n",
    "What do we need to repair this? How do we know it is repaired? When the predicted performance\n",
    "is close to what we know to be the true performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "The mistake is taking the cross-validation scores as an indication of the ability of the model to perform on new data. We need to instead split the data beforehand, keeping a small amount as testing data for the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong idea\n",
      "Scores on each subset:\n",
      "[ 0.61993769  0.571875    0.59375     0.578125    0.61442006]\n",
      "Average score and uncertainty: (59.56 +- 0.853)%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = make_data(N=2000, n_vars=50000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "select = SelectKBest(f_regression, k=20)\n",
    "X_sel = select.fit_transform(X_train, y_train)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, X_sel, y_train, cv=5, n_jobs=8)\n",
    "\n",
    "print(\"Wrong idea\")\n",
    "print(\"Scores on each subset:\")\n",
    "print(scores)\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instead, the actual score is:\n",
      "[ 0.55555556  0.51851852  0.51851852  0.48148148  0.62962963  0.51851852\n",
      "  0.51851852  0.44444444  0.37037037  0.59259259  0.55555556  0.51851852\n",
      "  0.38461538  0.68        0.4       ]\n",
      "Average score and uncertainty: (51.25 +- 2.180)%\n"
     ]
    }
   ],
   "source": [
    "print(\"Instead, the actual score is:\")\n",
    "X_sel_test = select.transform(X_test)\n",
    "scores = cross_val_score(clf, X_sel_test, y_test, cv=15, n_jobs=8)\n",
    "print(scores)\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
